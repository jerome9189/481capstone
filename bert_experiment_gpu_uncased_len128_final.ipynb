{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# reading training data\n",
    "# get data into np arrays\n",
    "df = pd.read_pickle(\"data/jerome_request_train.pkl\")\n",
    "df = pd.get_dummies(df, columns=['stance'])\n",
    "df['label'] = df[['stance_unrelated','stance_agree','stance_disagree','stance_discuss']].values.tolist()\n",
    "df['label'] = df['label'].apply(lambda x: x.index(1))\n",
    "#df_repeat = df[df['label'] != 0]\n",
    "#df = df.append([df_repeat]*2, ignore_index=True)\n",
    "# grab np values\n",
    "headlines = df['head'].values\n",
    "bodies = df['body'].values\n",
    "labels = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dev data\n",
    "# get data into np arrays\n",
    "df_val = pd.read_pickle(\"data/jerome_request_test.pkl\")\n",
    "df_val = pd.get_dummies(df_val, columns=['stance'])\n",
    "df_val['label'] = df_val[['stance_unrelated','stance_agree','stance_disagree','stance_discuss']].values.tolist()\n",
    "df_val['label'] = df_val['label'].apply(lambda x: x.index(1))\n",
    "# grab np values\n",
    "headlines_val = df_val['head'].values\n",
    "bodies_val = df_val['body'].values\n",
    "labels_val = df_val['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Hundreds of Palestinians flee floods in Gaza as Israel opens dams Hundreds of Palestinians were evacuated from their homes Sunday morning after Israeli authorities opened a number of dams near the border, flooding the Gaza Valley in the wake of a recent severe winter storm.\n",
      "\n",
      "The Gaza Ministry of Interior said in a statement that civil defense services and teams from the Ministry of Public Works had evacuated more than 80 families from both sides of the Gaza Valley (Wadi Gaza) after their homes flooded as water levels reached more than three meters.\n",
      "\n",
      "Gaza has experienced flooding in recent days amid a major storm that saw temperatures drop and frigid rain pour down.\n",
      "\n",
      "The storm displaced dozens and caused hardship for tens of thousands, including many of the approximately 110,000 Palestinians left homeless by Israel's assault over summer.\n",
      "\n",
      "The suffering is compounded by the fact that Israel has maintained a complete siege over Gaza for the last eight years, severely limiting electricity and the availability of fuel for generators. It has also prevented the displaced from rebuilding their homes, as construction materials are largely banned from entering.\n",
      "\n",
      "Gaza civil defense services spokesman Muhammad al-Midana warned that further harm could be caused if Israel opens up more dams in the area, noting that water is currently flowing at a high speed from the Israel border through the valley and into the Mediterranean sea.\n",
      "\n",
      "Evacuated families have been sent to shelters sponsored by UNRWA, the UN agency for Palestinian refugees, in al-Bureij refugee camp and in al-Zahra neighborhood in the central Gaza Strip.\n",
      "\n",
      "The Gaza Valley (Wadi Gaza) is a wetland located in the central Gaza Strip between al-Nuseirat refugee camp and al-Moghraqa. It is called HaBesor in Hebrew, and it flows from two streams -- one whose source runs from near Beersheba, and the other from near Hebron.\n",
      "\n",
      "Israeli dams on the river to collect rainwater have dried up the wetlands inside Gaza, and destroyed the only source of surface water in the area.\n",
      "\n",
      "Locals have continued to use it to dispose of their waste for lack of other ways to do so, however, creating an environmental hazard.\n",
      "\n",
      "This is not the first time Israeli authorities have opened the Gaza Valley dams.\n",
      "\n",
      "In Dec. 2013, Israeli authorities also opened the dams amid heavy flooding in the Gaza Strip. The resulting floods damaged dozens of homes and forces many families in the area from their homes.\n",
      "\n",
      "In 2010, the dams were opened as well, forcing 100 families from their homes. At the time civil defense services said that they had managed to save seven people who had been at risk of drowning.\n",
      "Token IDs: tensor([  101,  5606,  1997, 21524, 10574, 14295,  1999, 14474,  2004,  3956,\n",
      "         7480, 17278,   102,  5606,  1997, 21524,  2020, 13377,  2013,  2037,\n",
      "         5014,  4465,  2851,  2044,  5611,  4614,  2441,  1037,  2193,  1997,\n",
      "        17278,  2379,  1996,  3675,  1010,  9451,  1996, 14474,  3028,  1999,\n",
      "         1996,  5256,  1997,  1037,  3522,  5729,  3467,  4040,  1012,  1996,\n",
      "        14474,  3757,  1997,  4592,  2056,  1999,  1037,  4861,  2008,  2942,\n",
      "         3639,  2578,  1998,  2780,  2013,  1996,  3757,  1997,  2270,  2573,\n",
      "         2018, 13377,  2062,  2084,  3770,  2945,  2013,  2119,  3903,  1997,\n",
      "         1996, 14474,  3028,  1006, 28380, 14474,  1007,  2044,  2037,  5014,\n",
      "        10361,  2004,  2300,  3798,  2584,  2062,  2084,  2093,  5563,  1012,\n",
      "        14474,  2038,  5281,  9451,  1999,  3522,  2420, 13463,  1037,  2350,\n",
      "         4040,  2008,  2387,  7715,  4530,  1998, 10424,  8004,  3593,  4542,\n",
      "        10364,  2091,  1012,  1996,  4040, 12936,  9877,   102])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# tokenization\n",
    "input_ids = []\n",
    "#attention_masks = []\n",
    "\n",
    "for i in range(len(headlines)):\n",
    "    encoded_dict = tokenizer.encode(\n",
    "                        text=headlines[i],                      # headline to encode.\n",
    "                        text_pair=bodies[i],\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,\n",
    "                        pad_to_max_length=True,   # Pad & truncate all sentences.\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.   \n",
    "    #input_ids.append(encoded_dict['input_ids'])\n",
    "    input_ids.append(encoded_dict)\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    #attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "#attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', headlines[0], bodies[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Police find mass graves with at least '15 bodies' near Mexico town where 43 students disappeared after police clash Danny Boyle is directing the untitled film\n",
      "\n",
      "Seth Rogen is being eyed to play Apple co-founder Steve Wozniak in Sony’s Steve Jobs biopic.\n",
      "\n",
      "Danny Boyle is directing the untitled film, based on Walter Isaacson's book and adapted by Aaron Sorkin, which is one of the most anticipated biopics in recent years.\n",
      "\n",
      "Negotiations have not yet begun, and it’s not even clear if Rogen has an official offer, but the producers — Scott Rudin, Guymon Casady and Mark Gordon — have set their sights on the talent and are in talks.\n",
      "\n",
      "Of course, this may all be for naught as Christian Bale, the actor who is to play Jobs, is still in the midst of closing his deal. Sources say that dealmaking process is in a sensitive stage.\n",
      "\n",
      "Insiders say Boyle will is flying to Los Angeles to meet with actress to play one of the female leads, an assistant to Jobs. Insiders say that Jessica Chastain is one of the actresses on the meeting list.\n",
      "\n",
      "Wozniak, known as \"Woz,\" co-founded Apple with Jobs and Ronald Wayne. He first met Jobs when they worked at Atari and later was responsible for creating the early Apple computers.\n",
      "Token IDs: tensor([  101,  2610,  2424,  3742,  9729,  2007,  2012,  2560,  1005,  2321,\n",
      "         4230,  1005,  2379,  3290,  2237,  2073,  4724,  2493,  5419,  2044,\n",
      "         2610, 13249,   102,  6266, 16694,  2003,  9855,  1996, 24819,  2143,\n",
      "         6662, 20996,  6914,  2003,  2108,  7168,  2000,  2377,  6207,  2522,\n",
      "         1011,  3910,  3889, 24185,  2480,  6200,  2243,  1999,  8412,  1521,\n",
      "         1055,  3889,  5841, 16012, 24330,  1012,  6266, 16694,  2003,  9855,\n",
      "         1996, 24819,  2143,  1010,  2241,  2006,  4787,  7527,  3385,  1005,\n",
      "         1055,  2338,  1998,  5967,  2011,  7158,  2061, 26891,  1010,  2029,\n",
      "         2003,  2028,  1997,  1996,  2087, 11436, 16012, 24330,  2015,  1999,\n",
      "         3522,  2086,  1012,  7776,  2031,  2025,  2664,  5625,  1010,  1998,\n",
      "         2009,  1521,  1055,  2025,  2130,  3154,  2065, 20996,  6914,  2038,\n",
      "         2019,  2880,  3749,  1010,  2021,  1996,  6443,  1517,  3660, 21766,\n",
      "         8718,  1010,  3124,  8202, 14124,  5149,  1998,   102])\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "input_ids_val = []\n",
    "#attention_masks = []\n",
    "\n",
    "for i in range(len(headlines_val)):\n",
    "    encoded_dict = tokenizer.encode(\n",
    "                        text=headlines_val[i],                      # headline to encode.\n",
    "                        text_pair=bodies_val[i],\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,\n",
    "                        pad_to_max_length=True,   # Pad & truncate all sentences.\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.   \n",
    "    #input_ids.append(encoded_dict['input_ids'])\n",
    "    input_ids_val.append(encoded_dict)\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    #attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
    "#attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels_val = torch.tensor(labels_val)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', headlines_val[0], bodies_val[0])\n",
    "print('Token IDs:', input_ids_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45,437 training samples\n",
      "4,535 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "train_dataset = TensorDataset(input_ids, labels)\n",
    "val_dataset = TensorDataset(input_ids_val, labels_val)\n",
    "train_size = len(train_dataset)\n",
    "val_size = len(val_dataset)\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "Using GPU: TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('Using GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 4, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "model.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (4, 768)\n",
      "classifier.bias                                                 (4,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 24\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate fnc score and max fnc score\n",
    "def fnc_score(preds, labels):\n",
    "    y_pred = np.argmax(preds, axis=1).flatten()\n",
    "    y_true = labels.flatten()\n",
    "\n",
    "    # compute max_score = 0.25*unrelated + (agree+disagree+discuss)\n",
    "    total_count = torch.tensor(len(y_true))\n",
    "    unrelated_count = torch.sum(y_true == 0)\n",
    "    related_count = total_count - unrelated_count\n",
    "    max_score = 0.25 * unrelated_count + related_count\n",
    "\n",
    "    # compute score\n",
    "    unrelated_pred = y_pred == 0\n",
    "    unrelated_true = y_true == 0\n",
    "    correct_unrelated_count = torch.sum(unrelated_pred & unrelated_true)\n",
    "    correct_unrelated_count_score = 0.25 * correct_unrelated_count\n",
    "\n",
    "    is_related_mask = ~unrelated_pred\n",
    "    is_correct_mask = y_true == y_pred\n",
    "\n",
    "    combined_mask_correct_related = is_related_mask & is_correct_mask\n",
    "    correct_related_count = torch.sum(combined_mask_correct_related)\n",
    "    correct_related_count_score = 1.0 * correct_related_count\n",
    "\n",
    "    is_related_true_mask = ~unrelated_true\n",
    "    combined_mask_related = is_related_mask & is_related_true_mask\n",
    "    combined_mask_incorrect_related = combined_mask_related & ~combined_mask_correct_related\n",
    "    incorrect_related_count = torch.sum(combined_mask_incorrect_related)\n",
    "    incorrect_related_count_score = 0.25 * incorrect_related_count\n",
    "\n",
    "    score = correct_unrelated_count_score + correct_related_count_score + incorrect_related_count_score\n",
    "    return score, max_score\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return torch.sum(pred_flat == labels_flat).double() / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: knockknock in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (0.1.8.1)\n",
      "Requirement already satisfied: matrix-client in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from knockknock) (0.3.2)\n",
      "Requirement already satisfied: requests in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from knockknock) (2.23.0)\n",
      "Requirement already satisfied: python-telegram-bot in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from knockknock) (12.7)\n",
      "Requirement already satisfied: yagmail>=0.11.214 in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from knockknock) (0.11.224)\n",
      "Requirement already satisfied: twilio in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from knockknock) (6.40.0)\n",
      "Requirement already satisfied: keyring in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from knockknock) (21.2.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from requests->knockknock) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from requests->knockknock) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from requests->knockknock) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from requests->knockknock) (2020.4.5.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from python-telegram-bot->knockknock) (6.0.4)\n",
      "Requirement already satisfied: decorator>=4.4.0 in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from python-telegram-bot->knockknock) (4.4.2)\n",
      "Requirement already satisfied: cryptography in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from python-telegram-bot->knockknock) (2.9.2)\n",
      "Requirement already satisfied: future>=0.16.0 in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from python-telegram-bot->knockknock) (0.18.2)\n",
      "Requirement already satisfied: pytz in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from twilio->knockknock) (2020.1)\n",
      "Requirement already satisfied: PyJWT>=1.4.2 in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from twilio->knockknock) (1.7.1)\n",
      "Requirement already satisfied: six in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from twilio->knockknock) (1.14.0)\n",
      "Requirement already satisfied: SecretStorage>=3; sys_platform == \"linux\" in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from keyring->knockknock) (3.1.2)\n",
      "Requirement already satisfied: jeepney>=0.4.2; sys_platform == \"linux\" in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from keyring->knockknock) (0.4.3)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from cryptography->python-telegram-bot->knockknock) (1.14.0)\n",
      "Requirement already satisfied: pycparser in /homes/iws/jeromp/miniconda3/envs/transformers/lib/python3.8/site-packages (from cffi!=1.11.3,>=1.8->cryptography->python-telegram-bot->knockknock) (2.20)\n"
     ]
    }
   ],
   "source": [
    "# for sending notifications\n",
    "!pip install knockknock\n",
    "from knockknock import discord_sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "webhook_url = 'https://discordapp.com/api/webhooks/712190190101463063/S_txGBBy5qZkgQYPdYynzs5Sz_ogbVIgH1Pwck0xaMgrRFMYb0r4u1IuqC_gUxqQnVJr'\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "@discord_sender(webhook_url=webhook_url)\n",
    "def train(model, epochs, train_dataloader, validation_dataloader, device):\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    # For each epoch...\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "\n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "\n",
    "        # Put the model into training mode. Don't be mislead--the call to \n",
    "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "        # `dropout` and `batchnorm` layers behave differently during training\n",
    "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # Progress update every 100 batches.\n",
    "            if step % 100 == 0 and step != 0:\n",
    "                # Calculate elapsed time in minutes.\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "\n",
    "                # Report progress.\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "            # `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            #b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[1].to(device)\n",
    "\n",
    "            # Always clear any previously calculated gradients before performing a\n",
    "            # backward pass. PyTorch doesn't do this automatically because \n",
    "            # accumulating the gradients is \"convenient while training RNNs\". \n",
    "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "            model.zero_grad()        \n",
    "\n",
    "            # Perform a forward pass (evaluate the model on this training batch).\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # It returns different numbers of parameters depending on what arguments\n",
    "            # arge given and what flags are set. For our useage here, it returns\n",
    "            # the loss (because we provided labels) and the \"logits\"--the model\n",
    "            # outputs prior to activation.\n",
    "            loss, logits = model(input_ids=b_input_ids,\n",
    "                                 labels=b_labels)\n",
    "\n",
    "            # Accumulate the training loss over all of the batches so that we can\n",
    "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "            # single value; the `.item()` function just returns the Python value \n",
    "            # from the tensor.\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0.\n",
    "            # This is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and take a step using the computed gradient.\n",
    "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "            # modified based on their gradients, the learning rate, etc.\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the learning rate.\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_fnc_score = 0\n",
    "        total_eval_max_fnc_score = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "            # the `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            #b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[1].to(device)\n",
    "\n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "\n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # token_type_ids is the same as the \"segment ids\", which \n",
    "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "                # values prior to applying an activation function like the softmax.\n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                       token_type_ids=None, \n",
    "                                       labels=b_labels)\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu()\n",
    "            label_ids = b_labels.to('cpu')\n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "            # Calculate FNC score, max FNC score for this batch, and accumulate\n",
    "            b_fnc_score, b_max_fnc_score = fnc_score(logits, label_ids)\n",
    "            total_eval_fnc_score += b_fnc_score\n",
    "            total_eval_max_fnc_score += b_max_fnc_score\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_accuracy = (total_eval_accuracy / len(validation_dataloader)).item()\n",
    "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "        # Report fnc scores over validation run\n",
    "        total_eval_fnc_score = total_eval_fnc_score.item()\n",
    "        total_eval_max_fnc_score = total_eval_max_fnc_score.item()\n",
    "        relative_score = total_eval_fnc_score / total_eval_max_fnc_score\n",
    "        print(\"  FNC Score: {0:.2f}\".format(total_eval_fnc_score))\n",
    "        print(\"  Maximum Possible FNC Score: {0:.2f}\".format(total_eval_max_fnc_score))\n",
    "        print(\"  Relative FNC Score: {0:.2f}\".format(total_eval_fnc_score / total_eval_max_fnc_score))\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time,\n",
    "                'Valid. FNC Score': total_eval_fnc_score,\n",
    "                'Valid. Max FNC Score': total_eval_max_fnc_score,\n",
    "                'Relative FNC Score': relative_score\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "    return training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 24 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428094786/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  1,420.    Elapsed: 0:00:33.\n",
      "  Batch   200  of  1,420.    Elapsed: 0:01:07.\n",
      "  Batch   300  of  1,420.    Elapsed: 0:01:41.\n",
      "  Batch   400  of  1,420.    Elapsed: 0:02:15.\n",
      "  Batch   500  of  1,420.    Elapsed: 0:02:49.\n",
      "  Batch   600  of  1,420.    Elapsed: 0:03:23.\n",
      "  Batch   700  of  1,420.    Elapsed: 0:03:57.\n",
      "  Batch   800  of  1,420.    Elapsed: 0:04:31.\n",
      "  Batch   900  of  1,420.    Elapsed: 0:05:05.\n",
      "  Batch 1,000  of  1,420.    Elapsed: 0:05:39.\n",
      "  Batch 1,100  of  1,420.    Elapsed: 0:06:14.\n",
      "  Batch 1,200  of  1,420.    Elapsed: 0:06:48.\n",
      "  Batch 1,300  of  1,420.    Elapsed: 0:07:22.\n",
      "  Batch 1,400  of  1,420.    Elapsed: 0:07:56.\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epoch took: 0:08:03\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "  FNC Score: 1852.50\n",
      "  Maximum Possible FNC Score: 2061.50\n",
      "  Relative FNC Score: 0.90\n",
      "  Validation Loss: 0.20\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 2 / 24 ========\n",
      "Training...\n",
      "  Batch   100  of  1,420.    Elapsed: 0:00:34.\n",
      "  Batch   200  of  1,420.    Elapsed: 0:01:08.\n",
      "  Batch   300  of  1,420.    Elapsed: 0:01:42.\n",
      "  Batch   400  of  1,420.    Elapsed: 0:02:16.\n",
      "  Batch   500  of  1,420.    Elapsed: 0:02:50.\n",
      "  Batch   600  of  1,420.    Elapsed: 0:03:24.\n",
      "  Batch   700  of  1,420.    Elapsed: 0:03:58.\n",
      "  Batch   800  of  1,420.    Elapsed: 0:04:31.\n",
      "  Batch   900  of  1,420.    Elapsed: 0:05:05.\n",
      "  Batch 1,000  of  1,420.    Elapsed: 0:05:39.\n",
      "  Batch 1,100  of  1,420.    Elapsed: 0:06:13.\n",
      "  Batch 1,200  of  1,420.    Elapsed: 0:06:47.\n",
      "  Batch 1,300  of  1,420.    Elapsed: 0:07:20.\n",
      "  Batch 1,400  of  1,420.    Elapsed: 0:07:54.\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epoch took: 0:08:01\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  FNC Score: 1875.00\n",
      "  Maximum Possible FNC Score: 2061.50\n",
      "  Relative FNC Score: 0.91\n",
      "  Validation Loss: 0.22\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 3 / 24 ========\n",
      "Training...\n",
      "  Batch   100  of  1,420.    Elapsed: 0:00:34.\n",
      "  Batch   200  of  1,420.    Elapsed: 0:01:08.\n",
      "  Batch   300  of  1,420.    Elapsed: 0:01:42.\n",
      "  Batch   400  of  1,420.    Elapsed: 0:02:15.\n",
      "  Batch   500  of  1,420.    Elapsed: 0:02:49.\n",
      "  Batch   600  of  1,420.    Elapsed: 0:03:23.\n",
      "  Batch   700  of  1,420.    Elapsed: 0:03:57.\n",
      "  Batch   800  of  1,420.    Elapsed: 0:04:30.\n",
      "  Batch   900  of  1,420.    Elapsed: 0:05:04.\n",
      "  Batch 1,000  of  1,420.    Elapsed: 0:05:38.\n",
      "  Batch 1,100  of  1,420.    Elapsed: 0:06:12.\n",
      "  Batch 1,200  of  1,420.    Elapsed: 0:06:46.\n",
      "  Batch 1,300  of  1,420.    Elapsed: 0:07:20.\n",
      "  Batch 1,400  of  1,420.    Elapsed: 0:07:53.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epoch took: 0:08:00\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  FNC Score: 1889.00\n",
      "  Maximum Possible FNC Score: 2061.50\n",
      "  Relative FNC Score: 0.92\n",
      "  Validation Loss: 0.25\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 4 / 24 ========\n",
      "Training...\n",
      "  Batch   100  of  1,420.    Elapsed: 0:00:34.\n",
      "  Batch   200  of  1,420.    Elapsed: 0:01:08.\n",
      "  Batch   300  of  1,420.    Elapsed: 0:01:41.\n",
      "  Batch   400  of  1,420.    Elapsed: 0:02:15.\n",
      "  Batch   500  of  1,420.    Elapsed: 0:02:49.\n",
      "  Batch   600  of  1,420.    Elapsed: 0:03:23.\n",
      "  Batch   700  of  1,420.    Elapsed: 0:03:57.\n",
      "  Batch   800  of  1,420.    Elapsed: 0:04:30.\n",
      "  Batch   900  of  1,420.    Elapsed: 0:05:04.\n",
      "  Batch 1,000  of  1,420.    Elapsed: 0:05:38.\n",
      "  Batch 1,100  of  1,420.    Elapsed: 0:06:12.\n",
      "  Batch 1,200  of  1,420.    Elapsed: 0:06:46.\n",
      "  Batch 1,300  of  1,420.    Elapsed: 0:07:19.\n",
      "  Batch 1,400  of  1,420.    Elapsed: 0:07:53.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:08:00\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  FNC Score: 1920.00\n",
      "  Maximum Possible FNC Score: 2061.50\n",
      "  Relative FNC Score: 0.93\n",
      "  Validation Loss: 0.27\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 5 / 24 ========\n",
      "Training...\n",
      "  Batch   100  of  1,420.    Elapsed: 0:00:34.\n",
      "  Batch   200  of  1,420.    Elapsed: 0:01:08.\n",
      "  Batch   300  of  1,420.    Elapsed: 0:01:42.\n",
      "  Batch   400  of  1,420.    Elapsed: 0:02:15.\n",
      "  Batch   500  of  1,420.    Elapsed: 0:02:49.\n",
      "  Batch   600  of  1,420.    Elapsed: 0:03:23.\n",
      "  Batch   700  of  1,420.    Elapsed: 0:03:57.\n",
      "  Batch   800  of  1,420.    Elapsed: 0:04:31.\n",
      "  Batch   900  of  1,420.    Elapsed: 0:05:04.\n",
      "  Batch 1,000  of  1,420.    Elapsed: 0:05:38.\n",
      "  Batch 1,100  of  1,420.    Elapsed: 0:06:12.\n",
      "  Batch 1,200  of  1,420.    Elapsed: 0:06:46.\n",
      "  Batch 1,300  of  1,420.    Elapsed: 0:07:20.\n",
      "  Batch 1,400  of  1,420.    Elapsed: 0:07:53.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:08:00\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  FNC Score: 1895.25\n",
      "  Maximum Possible FNC Score: 2061.50\n",
      "  Relative FNC Score: 0.92\n",
      "  Validation Loss: 0.33\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 6 / 24 ========\n",
      "Training...\n",
      "  Batch   100  of  1,420.    Elapsed: 0:00:34.\n",
      "  Batch   200  of  1,420.    Elapsed: 0:01:08.\n",
      "  Batch   300  of  1,420.    Elapsed: 0:01:41.\n",
      "  Batch   400  of  1,420.    Elapsed: 0:02:15.\n",
      "  Batch   500  of  1,420.    Elapsed: 0:02:49.\n",
      "  Batch   600  of  1,420.    Elapsed: 0:03:23.\n",
      "  Batch   700  of  1,420.    Elapsed: 0:03:56.\n",
      "  Batch   800  of  1,420.    Elapsed: 0:04:30.\n",
      "  Batch   900  of  1,420.    Elapsed: 0:05:04.\n",
      "  Batch 1,000  of  1,420.    Elapsed: 0:05:38.\n",
      "  Batch 1,100  of  1,420.    Elapsed: 0:06:11.\n",
      "  Batch 1,200  of  1,420.    Elapsed: 0:06:45.\n",
      "  Batch 1,300  of  1,420.    Elapsed: 0:07:19.\n",
      "  Batch 1,400  of  1,420.    Elapsed: 0:07:53.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:07:59\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  FNC Score: 1903.25\n",
      "  Maximum Possible FNC Score: 2061.50\n",
      "  Relative FNC Score: 0.92\n",
      "  Validation Loss: 0.36\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 7 / 24 ========\n",
      "Training...\n",
      "  Batch   100  of  1,420.    Elapsed: 0:00:34.\n",
      "  Batch   200  of  1,420.    Elapsed: 0:01:08.\n",
      "  Batch   300  of  1,420.    Elapsed: 0:01:42.\n",
      "  Batch   400  of  1,420.    Elapsed: 0:02:16.\n",
      "  Batch   500  of  1,420.    Elapsed: 0:02:49.\n",
      "  Batch   600  of  1,420.    Elapsed: 0:03:23.\n",
      "  Batch   700  of  1,420.    Elapsed: 0:03:57.\n",
      "  Batch   800  of  1,420.    Elapsed: 0:04:31.\n",
      "  Batch   900  of  1,420.    Elapsed: 0:05:05.\n",
      "  Batch 1,000  of  1,420.    Elapsed: 0:05:38.\n",
      "  Batch 1,100  of  1,420.    Elapsed: 0:06:12.\n",
      "  Batch 1,200  of  1,420.    Elapsed: 0:06:46.\n",
      "  Batch 1,300  of  1,420.    Elapsed: 0:07:20.\n",
      "  Batch 1,400  of  1,420.    Elapsed: 0:07:53.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:08:00\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  FNC Score: 1908.00\n",
      "  Maximum Possible FNC Score: 2061.50\n",
      "  Relative FNC Score: 0.93\n",
      "  Validation Loss: 0.34\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 8 / 24 ========\n",
      "Training...\n",
      "  Batch   100  of  1,420.    Elapsed: 0:00:34.\n",
      "  Batch   200  of  1,420.    Elapsed: 0:01:08.\n",
      "  Batch   300  of  1,420.    Elapsed: 0:01:42.\n",
      "  Batch   400  of  1,420.    Elapsed: 0:02:15.\n",
      "  Batch   500  of  1,420.    Elapsed: 0:02:49.\n",
      "  Batch   600  of  1,420.    Elapsed: 0:03:23.\n",
      "  Batch   700  of  1,420.    Elapsed: 0:03:57.\n",
      "  Batch   800  of  1,420.    Elapsed: 0:04:31.\n",
      "  Batch   900  of  1,420.    Elapsed: 0:05:04.\n",
      "  Batch 1,000  of  1,420.    Elapsed: 0:05:38.\n",
      "  Batch 1,100  of  1,420.    Elapsed: 0:06:12.\n",
      "  Batch 1,200  of  1,420.    Elapsed: 0:06:46.\n",
      "  Batch 1,300  of  1,420.    Elapsed: 0:07:19.\n",
      "  Batch 1,400  of  1,420.    Elapsed: 0:07:53.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:08:00\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  FNC Score: 1914.25\n",
      "  Maximum Possible FNC Score: 2061.50\n",
      "  Relative FNC Score: 0.93\n",
      "  Validation Loss: 0.35\n",
      "  Validation took: 0:00:16\n",
      "\n",
      "======== Epoch 9 / 24 ========\n",
      "Training...\n",
      "  Batch   100  of  1,420.    Elapsed: 0:00:34.\n",
      "  Batch   200  of  1,420.    Elapsed: 0:01:08.\n",
      "  Batch   300  of  1,420.    Elapsed: 0:01:41.\n",
      "  Batch   400  of  1,420.    Elapsed: 0:02:15.\n",
      "  Batch   500  of  1,420.    Elapsed: 0:02:49.\n",
      "  Batch   600  of  1,420.    Elapsed: 0:03:23.\n",
      "  Batch   700  of  1,420.    Elapsed: 0:03:57.\n",
      "  Batch   800  of  1,420.    Elapsed: 0:04:30.\n",
      "  Batch   900  of  1,420.    Elapsed: 0:05:04.\n"
     ]
    }
   ],
   "source": [
    "training_stats = train(model, epochs, train_dataloader, validation_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1,\n",
       "  'Training Loss': 0.21228686320582327,\n",
       "  'Valid. Loss': 0.20095566584085914,\n",
       "  'Valid. Accur.': 0.9398346601347214,\n",
       "  'Training Time': '0:08:03',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1852.5,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.8986175115207373},\n",
       " {'epoch': 2,\n",
       "  'Training Loss': 0.06812953551358898,\n",
       "  'Valid. Loss': 0.2204453260703406,\n",
       "  'Valid. Accur.': 0.9451163502755665,\n",
       "  'Training Time': '0:08:01',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1875.0,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9095318942517584},\n",
       " {'epoch': 3,\n",
       "  'Training Loss': 0.02624504853492524,\n",
       "  'Valid. Loss': 0.25123276426391283,\n",
       "  'Valid. Accur.': 0.9502640845070423,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1889.0,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9163230657288383},\n",
       " {'epoch': 4,\n",
       "  'Training Loss': 0.014914164485638997,\n",
       "  'Valid. Loss': 0.2661228544844485,\n",
       "  'Valid. Accur.': 0.9575264084507042,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1920.0,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9313606597138007},\n",
       " {'epoch': 5,\n",
       "  'Training Loss': 0.011526459905907756,\n",
       "  'Valid. Loss': 0.32552347261062864,\n",
       "  'Valid. Accur.': 0.9509242957746479,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1895.25,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9193548387096774},\n",
       " {'epoch': 6,\n",
       "  'Training Loss': 0.0093812710304788,\n",
       "  'Valid. Loss': 0.3618490624162213,\n",
       "  'Valid. Accur.': 0.9511443661971831,\n",
       "  'Training Time': '0:07:59',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1903.25,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9232355081251515},\n",
       " {'epoch': 7,\n",
       "  'Training Loss': 0.0063058624240357845,\n",
       "  'Valid. Loss': 0.33702515689065865,\n",
       "  'Valid. Accur.': 0.9553257042253521,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1908.0,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9255396555905894},\n",
       " {'epoch': 8,\n",
       "  'Training Loss': 0.006230537934140852,\n",
       "  'Valid. Loss': 0.3546642767651577,\n",
       "  'Valid. Accur.': 0.9559859154929577,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1914.25,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9285714285714286},\n",
       " {'epoch': 9,\n",
       "  'Training Loss': 0.005963940538769978,\n",
       "  'Valid. Loss': 0.38875550577338314,\n",
       "  'Valid. Accur.': 0.9506181108389468,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1900.5,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9219015280135824},\n",
       " {'epoch': 10,\n",
       "  'Training Loss': 0.003776541590824808,\n",
       "  'Valid. Loss': 0.3862655949057408,\n",
       "  'Valid. Accur.': 0.9559859154929577,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1920.0,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9313606597138007},\n",
       " {'epoch': 11,\n",
       "  'Training Loss': 0.0037289104440249915,\n",
       "  'Valid. Loss': 0.3499667691255037,\n",
       "  'Valid. Accur.': 0.9577464788732394,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1923.25,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.932937181663837},\n",
       " {'epoch': 12,\n",
       "  'Training Loss': 0.003119167310356254,\n",
       "  'Valid. Loss': 0.38388086869555454,\n",
       "  'Valid. Accur.': 0.9575264084507042,\n",
       "  'Training Time': '0:08:01',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1924.5,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9335435362600049},\n",
       " {'epoch': 13,\n",
       "  'Training Loss': 0.0028457646661190408,\n",
       "  'Valid. Loss': 0.42982217420829866,\n",
       "  'Valid. Accur.': 0.9548855633802817,\n",
       "  'Training Time': '0:08:04',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1910.5,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9267523647829251},\n",
       " {'epoch': 14,\n",
       "  'Training Loss': 0.001767059941443555,\n",
       "  'Valid. Loss': 0.38626879731744107,\n",
       "  'Valid. Accur.': 0.9570862676056338,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1924.75,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9336648071792384},\n",
       " {'epoch': 15,\n",
       "  'Training Loss': 0.0027108961503703104,\n",
       "  'Valid. Loss': 0.41705690627485265,\n",
       "  'Valid. Accur.': 0.953125,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1905.25,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9242056754790201},\n",
       " {'epoch': 16,\n",
       "  'Training Loss': 0.001954669776477152,\n",
       "  'Valid. Loss': 0.43067428021619353,\n",
       "  'Valid. Accur.': 0.9522447183098591,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1899.75,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9215377152558817},\n",
       " {'epoch': 17,\n",
       "  'Training Loss': 0.0009436090106363172,\n",
       "  'Valid. Loss': 0.43723932906656704,\n",
       "  'Valid. Accur.': 0.9535651408450704,\n",
       "  'Training Time': '0:07:59',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1907.75,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9254183846713558},\n",
       " {'epoch': 18,\n",
       "  'Training Loss': 0.001546368404368922,\n",
       "  'Valid. Loss': 0.45188241674857405,\n",
       "  'Valid. Accur.': 0.9515845070422535,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1903.0,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.923114237205918},\n",
       " {'epoch': 19,\n",
       "  'Training Loss': 0.0015653148170463602,\n",
       "  'Valid. Loss': 0.41570995780437087,\n",
       "  'Valid. Accur.': 0.9533450704225352,\n",
       "  'Training Time': '0:07:59',\n",
       "  'Validation Time': '0:00:16',\n",
       "  'Valid. FNC Score': 1907.75,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9254183846713558},\n",
       " {'epoch': 20,\n",
       "  'Training Loss': 0.0008616912438778662,\n",
       "  'Valid. Loss': 0.41488345971573914,\n",
       "  'Valid. Accur.': 0.9544454225352113,\n",
       "  'Training Time': '0:08:00',\n",
       "  'Validation Time': '0:00:15',\n",
       "  'Valid. FNC Score': 1909.25,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9261460101867572},\n",
       " {'epoch': 21,\n",
       "  'Training Loss': 0.0005129942386409144,\n",
       "  'Valid. Loss': 0.43989185116550955,\n",
       "  'Valid. Accur.': 0.9575264084507042,\n",
       "  'Training Time': '0:07:57',\n",
       "  'Validation Time': '0:00:15',\n",
       "  'Valid. FNC Score': 1922.25,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9324520979869028},\n",
       " {'epoch': 22,\n",
       "  'Training Loss': 0.0005788661093569138,\n",
       "  'Valid. Loss': 0.4264756803676276,\n",
       "  'Valid. Accur.': 0.9555457746478874,\n",
       "  'Training Time': '0:07:54',\n",
       "  'Validation Time': '0:00:15',\n",
       "  'Valid. FNC Score': 1915.0,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9289352413291293},\n",
       " {'epoch': 23,\n",
       "  'Training Loss': 0.00045719513169343104,\n",
       "  'Valid. Loss': 0.47950170236364215,\n",
       "  'Valid. Accur.': 0.954225352112676,\n",
       "  'Training Time': '0:07:53',\n",
       "  'Validation Time': '0:00:15',\n",
       "  'Valid. FNC Score': 1911.0,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9269949066213922},\n",
       " {'epoch': 24,\n",
       "  'Training Loss': 0.0009901996108515306,\n",
       "  'Valid. Loss': 0.4699238658165789,\n",
       "  'Valid. Accur.': 0.9559859154929577,\n",
       "  'Training Time': '0:07:53',\n",
       "  'Validation Time': '0:00:15',\n",
       "  'Valid. FNC Score': 1916.5,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9296628668445307}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = [x['epoch'] for x in training_stats]\n",
    "training_loss = [x['Training Loss'] for x in training_stats]\n",
    "validation_loss  = [x['Valid. Loss'] for x in training_stats]\n",
    "relative_validation_fnc = [x['Relative FNC Score'] for x in training_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch, training_loss, label='train')\n",
    "plt.plot(epoch, validation_loss, label='validation')\n",
    "plt.title('Loss over training epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss_128_e24.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch, relative_validation_fnc)\n",
    "plt.title('Evaluation on Validation Set (max 1.00)')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Relative FNC Score')\n",
    "plt.savefig('fnc_128_e24.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_accuracy = [x['Valid. Accur.'] for x in training_stats]\n",
    "plt.plot(epoch, validation_accuracy)\n",
    "plt.title('Accuracy on Validation Set')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('accuracy_128_e24.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switching to train data to dump predictions\n",
    "#df_test = pd.read_csv(\"data/test_data.csv\")\n",
    "df_test = pd.read_pickle(\"data/jerome_request_test.pkl\")\n",
    "df_test = pd.get_dummies(df_test, columns=['stance'])\n",
    "df_test['label'] = df_test[['stance_unrelated','stance_agree','stance_disagree','stance_discuss']].values.tolist()\n",
    "df_test['label'] = df_test['label'].apply(lambda x: x.index(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_test = df_test['head'].values\n",
    "bodies_test = df_test['body'].values\n",
    "labels_test = df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Police find mass graves with at least '15 bodies' near Mexico town where 43 students disappeared after police clash Danny Boyle is directing the untitled film\n",
      "\n",
      "Seth Rogen is being eyed to play Apple co-founder Steve Wozniak in Sony’s Steve Jobs biopic.\n",
      "\n",
      "Danny Boyle is directing the untitled film, based on Walter Isaacson's book and adapted by Aaron Sorkin, which is one of the most anticipated biopics in recent years.\n",
      "\n",
      "Negotiations have not yet begun, and it’s not even clear if Rogen has an official offer, but the producers — Scott Rudin, Guymon Casady and Mark Gordon — have set their sights on the talent and are in talks.\n",
      "\n",
      "Of course, this may all be for naught as Christian Bale, the actor who is to play Jobs, is still in the midst of closing his deal. Sources say that dealmaking process is in a sensitive stage.\n",
      "\n",
      "Insiders say Boyle will is flying to Los Angeles to meet with actress to play one of the female leads, an assistant to Jobs. Insiders say that Jessica Chastain is one of the actresses on the meeting list.\n",
      "\n",
      "Wozniak, known as \"Woz,\" co-founded Apple with Jobs and Ronald Wayne. He first met Jobs when they worked at Atari and later was responsible for creating the early Apple computers.\n",
      "Token IDs: tensor([  101,  2610,  2424,  3742,  9729,  2007,  2012,  2560,  1005,  2321,\n",
      "         4230,  1005,  2379,  3290,  2237,  2073,  4724,  2493,  5419,  2044,\n",
      "         2610, 13249,   102,  6266, 16694,  2003,  9855,  1996, 24819,  2143,\n",
      "         6662, 20996,  6914,  2003,  2108,  7168,  2000,  2377,  6207,  2522,\n",
      "         1011,  3910,  3889, 24185,  2480,  6200,  2243,  1999,  8412,  1521,\n",
      "         1055,  3889,  5841, 16012, 24330,  1012,  6266, 16694,  2003,  9855,\n",
      "         1996, 24819,  2143,  1010,  2241,  2006,  4787,  7527,  3385,  1005,\n",
      "         1055,  2338,  1998,  5967,  2011,  7158,  2061, 26891,  1010,  2029,\n",
      "         2003,  2028,  1997,  1996,  2087, 11436, 16012, 24330,  2015,  1999,\n",
      "         3522,  2086,  1012,  7776,  2031,  2025,  2664,  5625,  1010,  1998,\n",
      "         2009,  1521,  1055,  2025,  2130,  3154,  2065, 20996,  6914,  2038,\n",
      "         2019,  2880,  3749,  1010,  2021,  1996,  6443,  1517,  3660, 21766,\n",
      "         8718,  1010,  3124,  8202, 14124,  5149,  1998,   102])\n"
     ]
    }
   ],
   "source": [
    "input_ids_test = []\n",
    "for i in range(len(headlines_test)):\n",
    "    encoded_dict = tokenizer.encode(\n",
    "                        text=headlines_test[i],                      # headline to encode.\n",
    "                        text_pair=bodies_test[i],\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,\n",
    "                        pad_to_max_length=True,   # Pad & truncate all sentences.\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.   \n",
    "    #input_ids.append(encoded_dict['input_ids'])\n",
    "    input_ids_test.append(encoded_dict)\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    #attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
    "#attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels_test = torch.tensor(labels_test)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', headlines_test[0], bodies_test[0])\n",
    "print('Token IDs:', input_ids_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,535 test samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "test_dataset = TensorDataset(input_ids_test, labels_test)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "\n",
    "print('{:>5,} test samples'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "            test_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_and_labels(preds, labels):\n",
    "    y_pred = np.argmax(preds, axis=1).flatten().numpy()\n",
    "    y_true = labels.flatten().numpy()\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test...\n",
      "  Accuracy: 0.96\n",
      "  FNC Score: 1916.50\n",
      "  Maximum Possible FNC Score: 2061.50\n",
      "  Relative FNC Score: 0.93\n",
      "  Test took: 0:00:14\n"
     ]
    }
   ],
   "source": [
    "print(\"Running test...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Put the model in evaluation mode--the dropout layers behave differently\n",
    "# during evaluation.\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "total_test_accuracy = 0\n",
    "total_test_fnc_score = 0\n",
    "total_test_max_fnc_score = 0\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for i,batch in enumerate(test_dataloader):\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "    # the `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    #b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[1].to(device)\n",
    "    \n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        (loss, logits) = model(b_input_ids, \n",
    "                               token_type_ids=None, \n",
    "                               labels=b_labels)\n",
    "\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu()\n",
    "    label_ids = b_labels.to('cpu')\n",
    "    \n",
    "    # saving test results\n",
    "    test_preds_b, test_labels_b = get_predictions_and_labels(logits, label_ids)\n",
    "    #test_predictions.extend(test_preds_b.tolist())\n",
    "    #test_labels.extend(test_labels_b.tolist())\n",
    "    \n",
    "    # for logits and labels\n",
    "    #test_predictions.extend(logits.numpy().tolist())\n",
    "    test_predictions.extend(np.argmax(logits, axis=1).flatten().tolist())\n",
    "    test_labels.extend(label_ids.tolist())\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    total_test_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Calculate FNC score, max FNC score for this batch, and accumulate\n",
    "    b_fnc_score, b_max_fnc_score = fnc_score(logits, label_ids)\n",
    "    total_test_fnc_score += b_fnc_score\n",
    "    total_test_max_fnc_score += b_max_fnc_score\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n",
    "print(\"  Accuracy: {0:.2f}\".format(avg_test_accuracy))\n",
    "\n",
    "# Report fnc scores over validation run\n",
    "relative_score_test = total_test_fnc_score / total_test_max_fnc_score\n",
    "print(\"  FNC Score: {0:.2f}\".format(total_test_fnc_score))\n",
    "print(\"  Maximum Possible FNC Score: {0:.2f}\".format(total_test_max_fnc_score))\n",
    "print(\"  Relative FNC Score: {0:.2f}\".format(relative_score_test))\n",
    "\n",
    "# Calculate the average loss over all of the batches.\n",
    "#avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "# Measure how long the validation run took.\n",
    "test_time = format_time(time.time() - t0)\n",
    "\n",
    "print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "# Record all statistics from this epoch.\n",
    "#return (\n",
    " #   {        \n",
    "  #      \n",
    " #       'Test. Accur.': avg_test_accuracy,\n",
    "#        'Test Time': test_time,\n",
    "  #      'Test FNC Score': total_test_fnc_score,\n",
    "   #     'Valid. Max FNC Score': total_test_max_fnc_score,\n",
    "   #     'Relative FNC Score': relative_score_test\n",
    "   # }\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('preds.pkl', 'wb') as f:\n",
    "    pickle.dump(test_predictions, f)\n",
    "\n",
    "with open('labels.pkl', 'wb') as f:\n",
    "    pickle.dump(test_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_preds_actuals = pd.DataFrame(list(zip(test_predictions, test_labels)), \n",
    "               columns =['prediction', 'actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_preds_actuals.to_csv(\"jerome_request_test_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('bert_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump training stats\n",
    "import pickle\n",
    "with open('bert_128/training_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(training_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_arr = np.array(test_predictions)\n",
    "test_labels_arr = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****HEAD****\n",
      "Nicaragua meteorite: Experts attempt to understand whether mysterious meteorite fell from passing Pitbull asteroid\n",
      "****HEAD****\n",
      "Say 'eh-oh!' to the Teletubbies SUN BABY - can you still recognise her after 19 years?\n",
      "****HEAD****\n",
      "New York City Plans to End Arrests for Possession of Small Amounts of Marijuana\n",
      "****HEAD****\n",
      "Meet Magneto Boy, the kid who attracts metal with his body\n",
      "****HEAD****\n",
      "Sugarhill Gang rapper Big Bank Hank dies at age 57\n",
      "****HEAD****\n",
      "Nicaragua asks U.S. for help investigating meteorite crater\n",
      "****HEAD****\n",
      "Meteor Leaves 40-Foot Crater Near Managua's Airport\n",
      "****HEAD****\n",
      "Homeless man receives $100... then shocks everyone with how he spends it\n",
      "****HEAD****\n",
      "NEWS/ You'll Never Guess How a Homeless Man Spent $100—Watch the Touching Video!\n",
      "****HEAD****\n",
      "NYC relaxes response to marijuana possession\n",
      "****HEAD****\n",
      "North Korea dictator Kim Jong-un undergoes surgery after breaking both ankles on military tour\n",
      "****HEAD****\n",
      "Rare meteorite impact causes blast in Nicaragua's capital, Managua\n",
      "****HEAD****\n",
      "Missing Libyan jetliners raise fears of terror attacks on 9/11\n",
      "****HEAD****\n",
      "Low-level marijuana possession could soon land you a ticket instead of arrest in New York City\n",
      "****HEAD****\n",
      "Meteorite leaves crater in Nicaraguan capital Managua\n",
      "****HEAD****\n",
      "Small Meteorite Strikes in Nicaragua's Capital City of Managua\n",
      "****HEAD****\n",
      "Bodies In Mexico Mass Grave Apparently Not Those Of Missing Students\n",
      "****HEAD****\n",
      "Meteorite leaves crater in Nicaraguan capital Managua\n",
      "****HEAD****\n",
      "Meet the X-BOY: Electric shock turns kid into MAGNETO\n",
      "****HEAD****\n",
      "NEWS/ Meet the Teletubbies Sun Baby: 19-Year-Old Jess Smith Reveals Herself as the Smiling Face Who Looked Over Teletubbyland\n",
      "****HEAD****\n",
      "Meteorite Strikes Nicaraguan Capital, Creates 16-Foot-Deep Crater\n",
      "****HEAD****\n",
      "It’s About To Get Harder To Be Arrested For Pot Possession In New York City\n",
      "****HEAD****\n",
      "Josh Paler Lin Gives A Homeless Man $100 And Follows Him To See How He Spends It\n",
      "****HEAD****\n",
      "Fidel Castro Dead? Yes, He Is… But The Cuban Leader Is Alive, Death Rumors Proven False\n",
      "****HEAD****\n",
      "NYPD to stop arrests for small amounts of marijuana\n",
      "****HEAD****\n",
      "What Glenn Beck Fears May Be Done With the 11 Missing Jets\n",
      "****HEAD****\n",
      "Doubts cast over Nicaragua meteorite claim\n",
      "****HEAD****\n",
      "Mexican students not among bodies found in mass graves\n",
      "****HEAD****\n",
      "Nicaragua Meteorite Impact Theory May Be Meteor-wrong\n",
      "****HEAD****\n",
      "Meteorite makes big crater in Nicaragua, government says\n",
      "****HEAD****\n",
      "Nicaragua asks U.S. for help investigating meteorite crater\n",
      "****HEAD****\n",
      "See the Crater a Meteorite Made in Nicaragua\n",
      "****HEAD****\n",
      "No, Robert Plant Didn’t Rip Up an $800 Million Contract\n",
      "****HEAD****\n",
      "North Korean leader Kim Jong-un not missing, just having ankle surgery\n",
      "****HEAD****\n",
      "Meteorite leaves crater in Nicaraguan capital Managua\n",
      "****HEAD****\n",
      "Big Bank Hank, US rapper and Sugarhill Gang founder member, dies at 57\n",
      "****HEAD****\n",
      "Small Meteorite Hits Managua\n",
      "****HEAD****\n",
      "Mystery woman behind the 'richest hands on the internet' revealed: Former pornstar 'makes $5m a year unwrapping Disney toys on YouTube'\n",
      "****HEAD****\n",
      "Real-life Magneto boy 'becomes living magnet' after getting massive electric shock from street lamp\n",
      "****HEAD****\n",
      "Rare meteorite impact causes blast in Nicaragua's capital, Managua\n",
      "****HEAD****\n",
      "SEE IT: California homeless man uses $100 gift to give food to others\n",
      "****HEAD****\n",
      "Meteorite leaves crater in Nicaraguan capital Managua\n",
      "****HEAD****\n",
      "Nasa questions whether crater in Nicaragua caused by meteorite\n",
      "****HEAD****\n",
      "Big Bank Hank of The Sugarhill Gang is dead at 57\n",
      "****HEAD****\n",
      "‘Teletubbies’ Sun Baby: Fans Freak Out Over Jess Smith, 19\n",
      "****HEAD****\n",
      "Meteorite Strikes Nicaraguan Capital, Creates 16-Foot-Deep Crater\n",
      "****HEAD****\n",
      "Rapper Big Bank Hank of Sugarhill Gang dies at 57\n",
      "****HEAD****\n",
      "See How This Homeless Man Spends A Hundred Dollars, And Keep A Tissue Handy [Video]\n",
      "****HEAD****\n",
      "This Woman Exposed Her Cheating Boyfriend With A Brilliant Christmas Gift\n",
      "****HEAD****\n",
      "A Mass Grave Points to a Student Massacre in Mexico\n",
      "****HEAD****\n",
      "This boy nearly died, now he has a superpower like Marvel’s Magneto\n",
      "****HEAD****\n",
      "After Giving A Homeless Man $100, This Guy Secretly Filmed Him...\n",
      "****HEAD****\n",
      "Rumor Robert Plant Ripped Up $800 Million Contract To Reunite Led Zeppelin Called 'Rubbish'\n",
      "****HEAD****\n",
      "Missing jetliners raise fear of new 9/11-style attacks after Libyan airport falls to Islamic militants\n",
      "****HEAD****\n",
      "Meteorite makes big crater in Nicaragua, government says\n",
      "****HEAD****\n",
      "NASA Raises Doubts About Reports of Nicaraguan Meteorite\n",
      "****HEAD****\n",
      "Isilkulskom student has gained superhero powers after shock\n",
      "****HEAD****\n",
      "Electric shock turns Russian boy into Marvel's Magneto\n",
      "****HEAD****\n",
      "Heartbroken girl spends week in KFC after getting dumped\n",
      "****HEAD****\n",
      "It was me! Student, 19, reveals SHE was the Teletubbies' giggling baby in the sky - and was paid just £250 and a box of toys\n",
      "****HEAD****\n",
      "Sugarhill Gang Rapper ‘Big Bank Hank’ Dies at 57\n",
      "****HEAD****\n",
      "Mexico hit by student massacre: At least 17 anti-corruption protesters 'rounded up, murdered and dumped in a mass grave' - and another 26 are missing\n",
      "****HEAD****\n",
      "Missing Mexico students not among 28 bodies found in mass grave\n",
      "****HEAD****\n",
      "Meteorite Leaves House-Sized Crater in Nicaragua’s Capital\n",
      "****HEAD****\n",
      "Sugarhill Gang's Big Bank Hank Dead At 57\n",
      "****HEAD****\n",
      "Singing polar bear facing ASBO after noise complaint\n",
      "****HEAD****\n",
      "Woman detained in Lebanon is not al-Baghdadi's wife, Iraq says\n",
      "****HEAD****\n",
      "Small Meteorite Strikes in Nicaragua's Capital City of Managua\n",
      "****HEAD****\n",
      "Comfort eating? Chinese woman, 26, spends an entire WEEK in KFC after being dumped by boyfriend\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_test[(test_predictions_arr == 1) & (test_labels_arr == 3)].iterrows():\n",
    "    print(\"****HEAD****\")\n",
    "    print(row['head'])\n",
    "    #print(\"****BODY****\")\n",
    "    #print(row['body'])\n",
    "    #print(\"**********************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 15448, 23879,  4221,  1024,  8519,  3535,  2000,  3305,  3251,\n",
       "          8075, 23879,  4221,  3062,  2013,  4458,  6770,  8569,  3363, 12175,\n",
       "           102,  8519,  2079,  2025,  2113,  3251,  1996, 23879,  4221,  4487,\n",
       "         11493,  2618, 22780,  2094,  2006,  4254,  2030,  2915,  2046,  1996,\n",
       "          2598, 13329,  2050, 25957,  4063,  7009,  2005,  1996,  2981,  1998,\n",
       "          2981,  2006,  4465,  6928,  5511,  2244,  2297,  8519,  2013,  2408,\n",
       "          1996,  2088,  2024,  7161,  2000,  3305,  3251,  1037,  8075,  9748,\n",
       "          2657,  1999,  1996, 15448,  2078,  3007,  1997, 24951, 19696,  2006,\n",
       "          5095,  2305,  2001,  3303,  2011,  1037, 23879,  4221,  2029,  3631,\n",
       "          2125,  2013,  1037,  4458, 12175,  1012, 29088,  3901,  1997,  1996,\n",
       "          2430,  2137,  2103,  2409, 12060,  2008,  2027,  2657,  1037,  5189,\n",
       "          8797,  2012,  2105,  2340,  9737,  1010,  2021,  2106,  2025,  2156,\n",
       "          2505,  5607,  2408,  1996,  3712,  1012,   102,     0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\n",
    "                        text='Nicaragua meteorite: Experts attempt to understand whether mysterious meteorite fell from passing Pitbull asteroid',                      # headline to encode.\n",
    "                        text_pair='''Experts do not know whether the meteorite disintegrated on impact or shot into the ground\n",
    "\n",
    "Kashmira Gander writes for the Independent and Independent on Sunday\n",
    "\n",
    "Monday 08 September 2014\n",
    "\n",
    "Experts from across the world are attempting to understand whether a mysterious bang heard in the Nicaraguan capital of Managua on Saturday night was caused by a meteorite which broke off from a passing asteroid.\n",
    "\n",
    "Baffled residents of the Central American city told reporters that they heard a loud boom at around 11pm, but did not see anything shoot across the sky. Meanwhile''',\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,\n",
    "                        pad_to_max_length=True,   # Pad & truncate all sentences.\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
