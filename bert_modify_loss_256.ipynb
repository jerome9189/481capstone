{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch.nn import CrossEntropyLoss, MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "Using GPU: TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:1\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('Using GPU:', torch.cuda.get_device_name(1))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [1.0, 1.0, 1.0, 1.0]\n",
    "class_weights = torch.FloatTensor(weights).cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceClassificationWeighted(BertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        weights=class_weights\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n",
    "            Labels for computing the sequence classification/regression loss.\n",
    "            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n",
    "            If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "    Returns:\n",
    "        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.BertConfig`) and inputs:\n",
    "        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n",
    "            Classification (or regression if config.num_labels==1) loss.\n",
    "        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n",
    "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
    "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
    "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n",
    "            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "    Examples::\n",
    "        from transformers import BertTokenizer, BertForSequenceClassification\n",
    "        import torch\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss, logits = outputs[:2]\n",
    "        \"\"\"\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss(weight=weights)\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"data/jerome_request_train.pkl\")\n",
    "df = pd.get_dummies(df, columns=['stance'])\n",
    "df['label'] = df[['stance_unrelated','stance_agree','stance_disagree','stance_discuss']].values.tolist()\n",
    "df['label'] = df['label'].apply(lambda x: x.index(1))\n",
    "# grab np values\n",
    "headlines = df['head'].values\n",
    "bodies = df['body'].values\n",
    "labels = df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_pickle(\"data/jerome_request_test.pkl\")\n",
    "df_val = pd.get_dummies(df_val, columns=['stance'])\n",
    "df_val['label'] = df_val[['stance_unrelated','stance_agree','stance_disagree','stance_discuss']].values.tolist()\n",
    "df_val['label'] = df_val['label'].apply(lambda x: x.index(1))\n",
    "# grab np values\n",
    "headlines_val = df_val['head'].values\n",
    "bodies_val = df_val['body'].values\n",
    "labels_val = df_val['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Hundreds of Palestinians flee floods in Gaza as Israel opens dams Hundreds of Palestinians were evacuated from their homes Sunday morning after Israeli authorities opened a number of dams near the border, flooding the Gaza Valley in the wake of a recent severe winter storm.\n",
      "\n",
      "The Gaza Ministry of Interior said in a statement that civil defense services and teams from the Ministry of Public Works had evacuated more than 80 families from both sides of the Gaza Valley (Wadi Gaza) after their homes flooded as water levels reached more than three meters.\n",
      "\n",
      "Gaza has experienced flooding in recent days amid a major storm that saw temperatures drop and frigid rain pour down.\n",
      "\n",
      "The storm displaced dozens and caused hardship for tens of thousands, including many of the approximately 110,000 Palestinians left homeless by Israel's assault over summer.\n",
      "\n",
      "The suffering is compounded by the fact that Israel has maintained a complete siege over Gaza for the last eight years, severely limiting electricity and the availability of fuel for generators. It has also prevented the displaced from rebuilding their homes, as construction materials are largely banned from entering.\n",
      "\n",
      "Gaza civil defense services spokesman Muhammad al-Midana warned that further harm could be caused if Israel opens up more dams in the area, noting that water is currently flowing at a high speed from the Israel border through the valley and into the Mediterranean sea.\n",
      "\n",
      "Evacuated families have been sent to shelters sponsored by UNRWA, the UN agency for Palestinian refugees, in al-Bureij refugee camp and in al-Zahra neighborhood in the central Gaza Strip.\n",
      "\n",
      "The Gaza Valley (Wadi Gaza) is a wetland located in the central Gaza Strip between al-Nuseirat refugee camp and al-Moghraqa. It is called HaBesor in Hebrew, and it flows from two streams -- one whose source runs from near Beersheba, and the other from near Hebron.\n",
      "\n",
      "Israeli dams on the river to collect rainwater have dried up the wetlands inside Gaza, and destroyed the only source of surface water in the area.\n",
      "\n",
      "Locals have continued to use it to dispose of their waste for lack of other ways to do so, however, creating an environmental hazard.\n",
      "\n",
      "This is not the first time Israeli authorities have opened the Gaza Valley dams.\n",
      "\n",
      "In Dec. 2013, Israeli authorities also opened the dams amid heavy flooding in the Gaza Strip. The resulting floods damaged dozens of homes and forces many families in the area from their homes.\n",
      "\n",
      "In 2010, the dams were opened as well, forcing 100 families from their homes. At the time civil defense services said that they had managed to save seven people who had been at risk of drowning.\n",
      "Token IDs: tensor([  101,  5606,  1997, 21524, 10574, 14295,  1999, 14474,  2004,  3956,\n",
      "         7480, 17278,   102,  5606,  1997, 21524,  2020, 13377,  2013,  2037,\n",
      "         5014,  4465,  2851,  2044,  5611,  4614,  2441,  1037,  2193,  1997,\n",
      "        17278,  2379,  1996,  3675,  1010,  9451,  1996, 14474,  3028,  1999,\n",
      "         1996,  5256,  1997,  1037,  3522,  5729,  3467,  4040,  1012,  1996,\n",
      "        14474,  3757,  1997,  4592,  2056,  1999,  1037,  4861,  2008,  2942,\n",
      "         3639,  2578,  1998,  2780,  2013,  1996,  3757,  1997,  2270,  2573,\n",
      "         2018, 13377,  2062,  2084,  3770,  2945,  2013,  2119,  3903,  1997,\n",
      "         1996, 14474,  3028,  1006, 28380, 14474,  1007,  2044,  2037,  5014,\n",
      "        10361,  2004,  2300,  3798,  2584,  2062,  2084,  2093,  5563,  1012,\n",
      "        14474,  2038,  5281,  9451,  1999,  3522,  2420, 13463,  1037,  2350,\n",
      "         4040,  2008,  2387,  7715,  4530,  1998, 10424,  8004,  3593,  4542,\n",
      "        10364,  2091,  1012,  1996,  4040, 12936,  9877,  1998,  3303, 26479,\n",
      "         2005, 15295,  1997,  5190,  1010,  2164,  2116,  1997,  1996,  3155,\n",
      "         7287,  1010,  2199, 21524,  2187, 11573,  2011,  3956,  1005,  1055,\n",
      "         6101,  2058,  2621,  1012,  1996,  6114,  2003,  7328,  2098,  2011,\n",
      "         1996,  2755,  2008,  3956,  2038,  5224,  1037,  3143,  6859,  2058,\n",
      "        14474,  2005,  1996,  2197,  2809,  2086,  1010,  8949, 14879,  6451,\n",
      "         1998,  1996, 11343,  1997,  4762,  2005, 16937,  1012,  2009,  2038,\n",
      "         2036,  8729,  1996, 12936,  2013, 14584,  2037,  5014,  1010,  2004,\n",
      "         2810,  4475,  2024,  4321,  7917,  2013,  5738,  1012, 14474,  2942,\n",
      "         3639,  2578, 14056,  7187,  2632,  1011,  3054,  5162,  7420,  2008,\n",
      "         2582,  7386,  2071,  2022,  3303,  2065,  3956,  7480,  2039,  2062,\n",
      "        17278,  1999,  1996,  2181,  1010,  9073,  2008,  2300,  2003,  2747,\n",
      "         8577,  2012,  1037,  2152,  3177,  2013,  1996,  3956,  3675,  2083,\n",
      "         1996,  3028,  1998,  2046,  1996,   102])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# tokenization\n",
    "input_ids = []\n",
    "#attention_masks = []\n",
    "\n",
    "for i in range(len(headlines)):\n",
    "    encoded_dict = tokenizer.encode(\n",
    "                        text=headlines[i],                      # headline to encode.\n",
    "                        text_pair=bodies[i],\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 256,\n",
    "                        pad_to_max_length=True,   # Pad & truncate all sentences.\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.   \n",
    "    #input_ids.append(encoded_dict['input_ids'])\n",
    "    input_ids.append(encoded_dict)\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    #attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "#attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', headlines[0], bodies[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Police find mass graves with at least '15 bodies' near Mexico town where 43 students disappeared after police clash Danny Boyle is directing the untitled film\n",
      "\n",
      "Seth Rogen is being eyed to play Apple co-founder Steve Wozniak in Sony’s Steve Jobs biopic.\n",
      "\n",
      "Danny Boyle is directing the untitled film, based on Walter Isaacson's book and adapted by Aaron Sorkin, which is one of the most anticipated biopics in recent years.\n",
      "\n",
      "Negotiations have not yet begun, and it’s not even clear if Rogen has an official offer, but the producers — Scott Rudin, Guymon Casady and Mark Gordon — have set their sights on the talent and are in talks.\n",
      "\n",
      "Of course, this may all be for naught as Christian Bale, the actor who is to play Jobs, is still in the midst of closing his deal. Sources say that dealmaking process is in a sensitive stage.\n",
      "\n",
      "Insiders say Boyle will is flying to Los Angeles to meet with actress to play one of the female leads, an assistant to Jobs. Insiders say that Jessica Chastain is one of the actresses on the meeting list.\n",
      "\n",
      "Wozniak, known as \"Woz,\" co-founded Apple with Jobs and Ronald Wayne. He first met Jobs when they worked at Atari and later was responsible for creating the early Apple computers.\n",
      "Token IDs: tensor([  101,  2610,  2424,  3742,  9729,  2007,  2012,  2560,  1005,  2321,\n",
      "         4230,  1005,  2379,  3290,  2237,  2073,  4724,  2493,  5419,  2044,\n",
      "         2610, 13249,   102,  6266, 16694,  2003,  9855,  1996, 24819,  2143,\n",
      "         6662, 20996,  6914,  2003,  2108,  7168,  2000,  2377,  6207,  2522,\n",
      "         1011,  3910,  3889, 24185,  2480,  6200,  2243,  1999,  8412,  1521,\n",
      "         1055,  3889,  5841, 16012, 24330,  1012,  6266, 16694,  2003,  9855,\n",
      "         1996, 24819,  2143,  1010,  2241,  2006,  4787,  7527,  3385,  1005,\n",
      "         1055,  2338,  1998,  5967,  2011,  7158,  2061, 26891,  1010,  2029,\n",
      "         2003,  2028,  1997,  1996,  2087, 11436, 16012, 24330,  2015,  1999,\n",
      "         3522,  2086,  1012,  7776,  2031,  2025,  2664,  5625,  1010,  1998,\n",
      "         2009,  1521,  1055,  2025,  2130,  3154,  2065, 20996,  6914,  2038,\n",
      "         2019,  2880,  3749,  1010,  2021,  1996,  6443,  1517,  3660, 21766,\n",
      "         8718,  1010,  3124,  8202, 14124,  5149,  1998,  2928,  5146,  1517,\n",
      "         2031,  2275,  2037, 15925,  2006,  1996,  5848,  1998,  2024,  1999,\n",
      "         7566,  1012,  1997,  2607,  1010,  2023,  2089,  2035,  2022,  2005,\n",
      "         6583, 18533,  2004,  3017, 28352,  2063,  1010,  1996,  3364,  2040,\n",
      "         2003,  2000,  2377,  5841,  1010,  2003,  2145,  1999,  1996, 12930,\n",
      "         1997,  5494,  2010,  3066,  1012,  4216,  2360,  2008,  3066, 12614,\n",
      "         2832,  2003,  1999,  1037,  7591,  2754,  1012, 25297,  2015,  2360,\n",
      "        16694,  2097,  2003,  3909,  2000,  3050,  3349,  2000,  3113,  2007,\n",
      "         3883,  2000,  2377,  2028,  1997,  1996,  2931,  5260,  1010,  2019,\n",
      "         3353,  2000,  5841,  1012, 25297,  2015,  2360,  2008,  8201, 15775,\n",
      "         9153,  2378,  2003,  2028,  1997,  1996, 19910,  2006,  1996,  3116,\n",
      "         2862,  1012, 24185,  2480,  6200,  2243,  1010,  2124,  2004,  1000,\n",
      "        24185,  2480,  1010,  1000,  2522,  1011,  2631,  6207,  2007,  5841,\n",
      "         1998,  8923,  6159,  1012,  2002,   102])\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "input_ids_val = []\n",
    "#attention_masks = []\n",
    "\n",
    "for i in range(len(headlines_val)):\n",
    "    encoded_dict = tokenizer.encode(\n",
    "                        text=headlines_val[i],                      # headline to encode.\n",
    "                        text_pair=bodies_val[i],\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 256,\n",
    "                        pad_to_max_length=True,   # Pad & truncate all sentences.\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.   \n",
    "    #input_ids.append(encoded_dict['input_ids'])\n",
    "    input_ids_val.append(encoded_dict)\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    #attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
    "#attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels_val = torch.tensor(labels_val)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', headlines_val[0], bodies_val[0])\n",
    "print('Token IDs:', input_ids_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45,437 training samples\n",
      "4,535 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "train_dataset = TensorDataset(input_ids, labels)\n",
    "val_dataset = TensorDataset(input_ids_val, labels_val)\n",
    "train_size = len(train_dataset)\n",
    "val_size = len(val_dataset)\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassificationWeighted(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassificationWeighted.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 4, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "model.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate fnc score and max fnc score\n",
    "def fnc_score(preds, labels):\n",
    "    y_pred = np.argmax(preds, axis=1).flatten()\n",
    "    y_true = labels.flatten()\n",
    "\n",
    "    # compute max_score = 0.25*unrelated + (agree+disagree+discuss)\n",
    "    total_count = torch.tensor(len(y_true))\n",
    "    unrelated_count = torch.sum(y_true == 0)\n",
    "    related_count = total_count - unrelated_count\n",
    "    max_score = 0.25 * unrelated_count + related_count\n",
    "\n",
    "    # compute score\n",
    "    unrelated_pred = y_pred == 0\n",
    "    unrelated_true = y_true == 0\n",
    "    correct_unrelated_count = torch.sum(unrelated_pred & unrelated_true)\n",
    "    correct_unrelated_count_score = 0.25 * correct_unrelated_count\n",
    "\n",
    "    is_related_mask = ~unrelated_pred\n",
    "    is_correct_mask = y_true == y_pred\n",
    "\n",
    "    combined_mask_correct_related = is_related_mask & is_correct_mask\n",
    "    correct_related_count = torch.sum(combined_mask_correct_related)\n",
    "    correct_related_count_score = 1.0 * correct_related_count\n",
    "\n",
    "    is_related_true_mask = ~unrelated_true\n",
    "    combined_mask_related = is_related_mask & is_related_true_mask\n",
    "    combined_mask_incorrect_related = combined_mask_related & ~combined_mask_correct_related\n",
    "    incorrect_related_count = torch.sum(combined_mask_incorrect_related)\n",
    "    incorrect_related_count_score = 0.25 * incorrect_related_count\n",
    "\n",
    "    score = correct_unrelated_count_score + correct_related_count_score + incorrect_related_count_score\n",
    "    return score, max_score\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return torch.sum(pred_flat == labels_flat).double() / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "def train(model, epochs, train_dataloader, validation_dataloader, device):\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    # For each epoch...\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "\n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Reset the total loss for this epoch.\n",
    "        total_train_loss = 0\n",
    "\n",
    "        # Put the model into training mode. Don't be mislead--the call to \n",
    "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "        # `dropout` and `batchnorm` layers behave differently during training\n",
    "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "            # Progress update every 100 batches.\n",
    "            if step % 100 == 0 and step != 0:\n",
    "                # Calculate elapsed time in minutes.\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "\n",
    "                # Report progress.\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "            # `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            #b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[1].to(device)\n",
    "\n",
    "            # Always clear any previously calculated gradients before performing a\n",
    "            # backward pass. PyTorch doesn't do this automatically because \n",
    "            # accumulating the gradients is \"convenient while training RNNs\". \n",
    "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "            model.zero_grad()        \n",
    "\n",
    "            # Perform a forward pass (evaluate the model on this training batch).\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # It returns different numbers of parameters depending on what arguments\n",
    "            # arge given and what flags are set. For our useage here, it returns\n",
    "            # the loss (because we provided labels) and the \"logits\"--the model\n",
    "            # outputs prior to activation.\n",
    "            loss, logits = model(input_ids=b_input_ids,\n",
    "                                 labels=b_labels)\n",
    "\n",
    "            # Accumulate the training loss over all of the batches so that we can\n",
    "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "            # single value; the `.item()` function just returns the Python value \n",
    "            # from the tensor.\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate the gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0.\n",
    "            # This is to help prevent the \"exploding gradients\" problem.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and take a step using the computed gradient.\n",
    "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "            # modified based on their gradients, the learning rate, etc.\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the learning rate.\n",
    "            scheduler.step()\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "\n",
    "        # Measure how long this epoch took.\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_fnc_score = 0\n",
    "        total_eval_max_fnc_score = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in validation_dataloader:\n",
    "\n",
    "            # Unpack this training batch from our dataloader. \n",
    "            #\n",
    "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "            # the `to` method.\n",
    "            #\n",
    "            # `batch` contains three pytorch tensors:\n",
    "            #   [0]: input ids \n",
    "            #   [1]: attention masks\n",
    "            #   [2]: labels \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            #b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[1].to(device)\n",
    "\n",
    "            # Tell pytorch not to bother with constructing the compute graph during\n",
    "            # the forward pass, since this is only needed for backprop (training).\n",
    "            with torch.no_grad():        \n",
    "\n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # token_type_ids is the same as the \"segment ids\", which \n",
    "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "                # values prior to applying an activation function like the softmax.\n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                       token_type_ids=None, \n",
    "                                       labels=b_labels)\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu()\n",
    "            label_ids = b_labels.to('cpu')\n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "            # Calculate FNC score, max FNC score for this batch, and accumulate\n",
    "            b_fnc_score, b_max_fnc_score = fnc_score(logits, label_ids)\n",
    "            total_eval_fnc_score += b_fnc_score\n",
    "            total_eval_max_fnc_score += b_max_fnc_score\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_accuracy = (total_eval_accuracy / len(validation_dataloader)).item()\n",
    "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "        # Report fnc scores over validation run\n",
    "        total_eval_fnc_score = total_eval_fnc_score.item()\n",
    "        total_eval_max_fnc_score = total_eval_max_fnc_score.item()\n",
    "        relative_score = total_eval_fnc_score / total_eval_max_fnc_score\n",
    "        print(\"  FNC Score: {0:.2f}\".format(total_eval_fnc_score))\n",
    "        print(\"  Maximum Possible FNC Score: {0:.2f}\".format(total_eval_max_fnc_score))\n",
    "        print(\"  Relative FNC Score: {0:.2f}\".format(total_eval_fnc_score / total_eval_max_fnc_score))\n",
    "\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time,\n",
    "                'Valid. FNC Score': total_eval_fnc_score,\n",
    "                'Valid. Max FNC Score': total_eval_max_fnc_score,\n",
    "                'Relative FNC Score': relative_score\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "    return training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n",
      "  Batch   100  of  1,420.    Elapsed: 0:01:04.\n",
      "  Batch   200  of  1,420.    Elapsed: 0:02:08.\n",
      "  Batch   300  of  1,420.    Elapsed: 0:03:13.\n",
      "  Batch   400  of  1,420.    Elapsed: 0:04:19.\n",
      "  Batch   500  of  1,420.    Elapsed: 0:05:24.\n",
      "  Batch   600  of  1,420.    Elapsed: 0:06:30.\n",
      "  Batch   700  of  1,420.    Elapsed: 0:07:36.\n",
      "  Batch   800  of  1,420.    Elapsed: 0:08:42.\n",
      "  Batch   900  of  1,420.    Elapsed: 0:09:47.\n",
      "  Batch 1,000  of  1,420.    Elapsed: 0:10:53.\n",
      "  Batch 1,100  of  1,420.    Elapsed: 0:11:59.\n",
      "  Batch 1,200  of  1,420.    Elapsed: 0:13:05.\n",
      "  Batch 1,300  of  1,420.    Elapsed: 0:14:10.\n",
      "  Batch 1,400  of  1,420.    Elapsed: 0:15:16.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:15:29\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  FNC Score: 1903.25\n",
      "  Maximum Possible FNC Score: 2061.50\n",
      "  Relative FNC Score: 0.92\n",
      "  Validation Loss: 0.23\n",
      "  Validation took: 0:00:31\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:16:00 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "training_stats = train(model, epochs, train_dataloader, validation_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1,\n",
       "  'Training Loss': 0.014034045911246492,\n",
       "  'Valid. Loss': 0.2255572105239762,\n",
       "  'Valid. Accur.': 0.9535651408450704,\n",
       "  'Training Time': '0:15:29',\n",
       "  'Validation Time': '0:00:31',\n",
       "  'Valid. FNC Score': 1903.25,\n",
       "  'Valid. Max FNC Score': 2061.5,\n",
       "  'Relative FNC Score': 0.9232355081251515}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = [x['epoch'] for x in training_stats]\n",
    "training_loss = [x['Training Loss'] for x in training_stats]\n",
    "validation_loss  = [x['Valid. Loss'] for x in training_stats]\n",
    "relative_validation_fnc = [x['Relative FNC Score'] for x in training_stats]\n",
    "validation_accuracy = [x['Valid. Accur.'] for x in training_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch, training_loss, label='train')\n",
    "plt.plot(epoch, validation_loss, label='validation')\n",
    "plt.title('Loss over training epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss_256.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch, relative_validation_fnc)\n",
    "plt.title('Evaluation on Validation Set (max 1.00)')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Relative FNC Score')\n",
    "plt.savefig('fnc_256.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch, validation_accuracy)\n",
    "plt.title('Accuracy on Validation Set')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.savefig('accuracy_256.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('training_stats_256.pkl', 'wb') as f:\n",
    "    pickle.dump(training_stats, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
